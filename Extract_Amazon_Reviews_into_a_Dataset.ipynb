{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Scraping Amazon Reviews into a Panda Dataframe**"
      ],
      "metadata": {
        "id": "hWeiFk2lbX5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing all the libraries\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "metadata": {
        "id": "Oi_V-93Ximlm"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using personal header\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36', 'Accept-Language': 'en-US, en;q=0.5'}"
      ],
      "metadata": {
        "id": "yW83t9V5Z5Fa"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating def function to return the data\n",
        "def amazon_product_reviews(url):\n",
        "\n",
        "    #Initialize lists to store review data\n",
        "    reviews_list = []\n",
        "    ratings_list = []\n",
        "    dates_list = []\n",
        "\n",
        "    #Make a request to the specified URL to get the page contents\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    #Find all review containers on the page using the 'data-hook' attribute\n",
        "    reviews = soup.find_all('div', {'data-hook': 'review'})\n",
        "\n",
        "    #Extract the data and store in respective lists\n",
        "    for review in reviews:\n",
        "        review_text = review.find('span', {'data-hook': 'review-body'}).text.strip()\n",
        "        review_rating = float(review.find('i', {'data-hook': 'review-star-rating'}).text.replace(' out of 5 stars', '').strip())\n",
        "        review_date = int(review.find('span', {\"data-hook\": \"review-date\"}).text[-4:].strip())\n",
        "\n",
        "        reviews_list.append(review_text)\n",
        "        ratings_list.append(review_rating)\n",
        "        dates_list.append(review_date)\n",
        "\n",
        "    #Returning the extracted data\n",
        "    return reviews_list, ratings_list, dates_list"
      ],
      "metadata": {
        "id": "LaexHF-qZ7gO"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #Define the product URL for Amazon's product review\n",
        "    product_url = 'https://www.amazon.com/New-Apple-AirPods-Max-Space/product-reviews/B08PZHYWJS/ref=cm_cr_arp_d_paging_btm_next_{}?ie=UTF8&reviewerType=all_reviews'\n",
        "\n",
        "    #Call the 'amazon_product_reviews' function to extract data\n",
        "    reviews, ratings, dates = amazon_product_reviews(product_url)"
      ],
      "metadata": {
        "id": "fDyd2m2cZ-n7"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Coverting the data into a Panda Dataframe\n",
        "df = pd.DataFrame({'Reviews': reviews, 'Ratings': ratings, 'Date': dates})\n",
        "print(df)"
      ],
      "metadata": {
        "id": "M540uVPxaGyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Coverting the Panda Dataframe into a CSV file\n",
        "df.to_csv(r'E:\\reviews.csv',index=True)"
      ],
      "metadata": {
        "id": "GfrenqT1ogww"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}